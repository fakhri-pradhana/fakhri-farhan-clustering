---
title : "FACTOR ANALYSIS dan SVM Tugas Besar FSD"
output : html_document
author : "Fakhri Ilham (18523060) & Muhammad Farhan (18523099)"
---


**dataset yang digunakan adalah FIFA 2018 Man of the Match**

dataset dapat diunduh melalui link dibawah:
https://www.kaggle.com/mathan/fifa-2018-match-statistics

**Karakteristik dataset :**

1. tersusun dari 128 baris dan 27 fitur
2. Merupakan dataset dengan tipe data string dan numerik
3. Memiliki data yang kosong atau `NA` (sehingga akan dilakukan preprocessing untuk mengganti `NA` menjadi 0)

## **LANGKAH 1 (FA):**

* Melakukan import dataset dengan membaca csv yang berlokasi dalam satu folder proyek
* mereduksi fitur dengan feature selection `c(4:20, 22)`
* melakukan replacement nilai kolom NA menjadi 0 dengan fungsi `is.na()`
```{r}
#install.packages('psych')
library(psych)
myData <- read.csv("FIFA 2018 Statistics.csv")
fifa_results <- myData[,c(4:20, 22)]

fifa_results$X1st.Goal[is.na(fifa_results$X1st.Goal)] <- 0

head(fifa_results)
```

### **LANGKAH 2 (FA):**

Cari tahu variabel mana yang dapat dipertimbangkan untuk FA:

Untuk mengetahui variable mana yang paling relevan kita dapat menggunakan Tes Kaiser-Meyer-Olkin (KMO). 
Fungsi `KMO()` dari package `psych` akan memeriksa apakah suatu variabel cocok untuk Factor Analysis

* Membuat matriks korelasi dengan fungsi `cor(fifa_results)`
* Menggunakan fungsi `KMO()` untuk memeriksa kecocokan variable
```{r}
df_corr <- cor(fifa_results)
KMO(df_corr)
```

**Catatan :**

* MSA (ukuran kecukupan sampling) adalah ukuran untuk mengecualikan variabel. 
* Jika MSA <0,5 variabel akan tereliminasi. 
* Variabel dengan MSA> 0.6 akan cocok, 
* variabel dengan MSA> 0.8 akan sangat cocok untuk Factor Analysis 

Dengan catatan diatas kita dapat mengeliminasi variabel :

* "On.Target", 
* "Off.Target", 
* "Blocked", 
* "Offsides", 
* "Distance.Covered.Kms", 
* "Yellow.Red", 
* "Red", 
* "first_goal"

### **LANGKAH 3 (FA):**

Mengeliminasi variable yang tidak dibutuhkan dengan memilih fitur `c(1:3, 7, 9:12, 14:15, 17)`

```{r}
df1_fifaRes <- fifa_results[,c(1:3, 7, 9:12, 14:15, 17)]
head(df1_fifaRes)
```

### **LANGKAH 4 (FA):**

* Membuat matriks korelasi dengan variable yang sudah dipilih dari `df1_fifaRes`
* Memberi warna untuk mempermudah visualisasi 
* Tambahkan koefisien korelasi dengan code `addCoef.col = "black"`
* Memberi warna label dan rotasinya dengan ` tl.col="black", tl.srt=45`
* sembunyikan koefisien korelasi pada diagonal utama `diag=FALSE`
* Memvisualisasikan korelasi matriks kedalam bentuk tabel `round(df1_corr, 2)`

```{r}
library(corrplot)
df1_corr <- cor(df1_fifaRes) 
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(round(df1_corr, 2), method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", 
         tl.col="black", tl.srt=45,
         diag=FALSE)
round(df1_corr, 2)
```

Setelah melakukan visualisasi matriks correlation, 
kita tahu berapa banyak faktor yang perlu digunakan dari grafik yang diberikan di atas (yaitu 4 faktor). 

pengambilan 4 faktor ini didasari oleh sebaran warna yang dapat terlihat secara kasat mata

FA akan dilakukan dengan fungsi `fa()` dari package `psych` dengan *mem-passing parameter* : matriks korelasi, jumlah faktor, dan rotasi.

### **LANGKAH 5 (FA):**

* Menggunakan library `GPArotation` dan `psych`
* Meng-assign `nfactors` menjadi 4 berdasarkan rekomendasi dari matriks korelasi dari langkah sebelumnya
```{r}
library('GPArotation')
library(psych)
nfactors <- 4 
nvars <- dim(df1_corr)[1]
factors <- fa(r = df1_corr, nfactors = nfactors, rotate = "Varimax")
factors
```


### **LANGKAH 6 (FA):**

Melakukan plotting untuk mendapatkan visualisasi FA

```{r}
load <- factors$loadings[,1:4] 
fa.diagram(factors, digits = 2)
```

**Temuan dari plotting :**

Setelah melakukan plotting kita mendapatkan bahwa :

* **Faktor 1** : Kontrol Permainan ('Ball Possesion', 'Passes', dan 'Pass Accuracy')
* **Faktor 2** : Teknik Penyerangan ('Corners' dan 'Attempts')
* **Faktor 3** : Peraturan permainan ('Fouls Committed', dan 'Yellow Card')
* **Faktor 4** : Lain-lain ( 'Free Kicks' ,dan 'Saves') dan memiliki nilai negatif

### **LANGKAH 7 (FA):**
```{r}
plot(load, type="n")
text(load,labels=names(factors),cex=.7) 
```

Terlihat dalam plot, sebaran **factor loading** memiliki nilai yang sangat variatif

### **LANGKAH 8 (FA):**

Terdapa cara lain untuk dapat menentukan jumlah faktor, kita dapat menggunakan bantuan **scree plot** apabila kita tidak memiliki dasar ilmiah untuk menentukan jumlah faktor. 

```{r}
library('psy')
scree.plot(df1_corr)
```

**Temuan dari Screeplot :**

* jumlah faktor yang disarankan adalah 3 faktor
* hal ini juga menjadi alasan mengapa plotting FA sebelumnya (dengan metode **Correlation Matrix** menunjukkan bahwa faktor ke-4 sangat sedikit menunjukkan hubungannya dengan fitur-fitur terkait, bahkan ada yang bernilai negatif.


### **LANGKAH 9 (SVM) :**

Membuat variable R baru dengan nama `filteredFifa`, dengan memasukkan beberapa fitur dari dataset berbekal pengetahuan yang didapatkan dari FA

Pengetahuan yand didapatkan adalah memilih 4 fitur dengan nilai terbesar untuk dijadikan sebagai **data training** dan **data testing** dalam SVM

```{r}
library(psych)
filteredFifa <- myData[,c(5, 10, 17, 12)]

head(filteredFifa)
```

### **LANGKAH 10 (SVM Fitur Ball.Possesion) :**

#### **Melakukan training dan testing terhadap fitur _Ball.Possesion_ yang merupakan perwakilan dari Factor pertama**



1. Menggunakan library `caret` yang merupakan package untuk *Classification and Regression Training*
```{r}
library(caret)
```


2. Melakukan data splitting dengan komposisi 70% training dan 30% testing dengan method `createDataPartition()`
3. Mengassign hasil split ke dalam variable `trainingBallPossesion` dan `testingBallPossesion`
4. Mengecek jumlah dimensi dari data dengan method `dim()`
```{r}
intrainBallPossesion <- createDataPartition(y=filteredFifa$Ball.Possession.., p=0.7, list=FALSE)
trainingBallPossesion <- filteredFifa[intrainBallPossesion,]
testingBallPossesion <- filteredFifa[-intrainBallPossesion,]

dim(trainingBallPossesion)
dim(testingBallPossesion)

```

5. Melakukan `set` terhadap `seed`
```{r}
set.seed(132)
```

6. sad
```{r}
trainingBallPossesion[["Ball.Possession.."]] = factor(trainingBallPossesion[["Ball.Possession.."]])
```

7. Membagi data menjadi *training* dan *testing* ke dalam 5 lipatan atau **5-fold cross validation** dengan menggunakan fugsi `trainControl()`
```{r}
trainControl_BallPossesion <- trainControl(method = "repeatedcv", number=2, repeats = 3)
```

8. Membuat model SVM dari data `trainingBallPossesion` menggunakan fungsi `train()` dari library `caret`
```{r}
svmLinear_BallPossesion <- train(Ball.Possession.. ~., data = trainingBallPossesion, method = "svmLinear", 
                        trControl = trainControl_BallPossesion,
                        preProcess = c("center", "scale"),
                        tuneLength = 10)
```

9. Akurasi dari tiap-tiap fold dari proses _training_ sebelumnya dapat dilihat dengan
```{r}
svmLinear_BallPossesion$resample
```

**Catatan dan temuan :**

* dari proses pembangunan model ternyata diperoleh bahwa akurasi dari model sangatlah buruk
* sehingga dapat disimpulkan bahwa model SVM tidak cocok untuk dataset ini
* Mari kita lanjutkan dengan dengan menghitung prediksi dari model untuk mendukung argumen poin 2

9. Melakukan prediksi terhadap model SVM setelah membangun model dengan fungsi `predict()`
```{r}
prediction_BallPossesion <- predict(svmLinear_BallPossesion, newdata =testingBallPossesion)
show(prediction_BallPossesion)
```

**Catatan dan temuan :**

* dapat kita lihat bahwa nilai dari prediksi sebagian besar meleset dari data sebenarnya
* Mari kita lanjutkan dengan melihat _confussion matrix_ model SVM

```{r}
confusionMatrix(svmLinear_BallPossesion)
```

**Catatan dan temuan :**

* dapat kita simpulkan bahwa model SVM tidak disarankan untuk dataset ini karena akurasi memang terbukti sangat rendah dilihat dari nilai `Accuracy (average)` diatas
* Mari kita buat model SVM untuk kasus fitur lain


### **LANGKAH 11 (SVM Fitur Corners) :**

#### **Melakukan training dan testing terhadap fitur _Corners_ yang merupakan perwakilan dari Factor kedua**

1. Menggunakan library `caret` yang merupakan package untuk *Classification and Regression Training*
```{r}
library(caret)
```


2. Melakukan data splitting dengan komposisi 70% training dan 30% testing dengan method `createDataPartition()`
3. Mengassign hasil split ke dalam variable `trainingCorners` dan `testingCorners`
4. Mengecek jumlah dimensi dari data dengan method `dim()`
```{r}
intrainCorners <- createDataPartition(y=filteredFifa$Corners, p=0.7, list=FALSE)
trainingCorners <- filteredFifa[intrainCorners,]
testingCorners <- filteredFifa[-intrainCorners,]

dim(trainingCorners)
dim(testingCorners)

```

5. Melakukan `set` terhadap `seed`
```{r}
set.seed(132)
```

6. sad
```{r}
trainingCorners[["Corners"]] = factor(trainingCorners[["Corners"]])
```

7. Membagi data menjadi *training* dan *testing* ke dalam 5 lipatan atau **5-fold cross validation** dengan menggunakan fugsi `trainControl()`
```{r}
trainControl_Corners <- trainControl(method = "repeatedcv", number=2, repeats = 3)
```

8. Membuat model SVM dari data `trainingCorners` menggunakan fungsi `train()` dari library `caret`
```{r}
svmLinear_Corners <- train(Corners ~., data = trainingCorners, method = "svmLinear", 
                        trControl = trainControl_Corners,
                        preProcess = c("center", "scale"),
                        tuneLength = 10)
```

9. Akurasi dari tiap-tiap fold dari proses _training_ sebelumnya dapat dilihat dengan
```{r}
svmLinear_Corners$resample
```

**Catatan dan temuan :**

* dari proses pembangunan model ternyata diperoleh bahwa akurasi dari model dengan fitur Corners masih terbilang rendah
* sehingga dapat disimpulkan bahwa model SVM masih belum direkomendasikan untuk dataset ini
* Mari kita lanjutkan dengan dengan menghitung prediksi dari model untuk mendukung argumen poin 2

9. Melakukan prediksi terhadap model SVM setelah membangun model dengan fungsi `predict()`
```{r}
prediction_Corners <- predict(svmLinear_Corners, newdata =testingCorners)
show(prediction_Corners)
show(testingCorners$Corners)
```

**Catatan dan temuan :**

* dapat kita lihat bahwa nilai dari prediksi sebagian besar meleset dari data sebenarnya
* Mari kita lanjutkan dengan melihat _confussion matrix_ model SVM dengan fitur Corners ini

```{r}
confusionMatrix(svmLinear_Corners)
```

**Catatan dan temuan :**

* dapat kita simpulkan bahwa model SVM tidak disarankan untuk dataset ini karena akurasi memang masih terbukti sangat rendah dilihat dari nilai `Accuracy (average)` diatas
* Sehingga dapat disimpulkan SVM juga tidak cocok untuk fitur lain dari dataset ini



